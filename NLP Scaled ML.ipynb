{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('blogtext.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 4.85 s, total: 1min 30s\n",
      "Wall time: 18min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Here we import my custom cleaner script, clean.py. I parallelize the function to run faster here, to work when scaling. \n",
    "#Using 11 threads to run the script and 1 to manage the multiprocessing.\n",
    "import clean\n",
    "from joblib import Parallel, delayed\n",
    "df['tokens'] = Parallel(n_jobs=11)(delayed(clean.clean)(line) for line in df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    info have find page psf file have wait until t...\n",
       "1    team member drives van der lang mail ruby die ...\n",
       "2    nader van kernfusie barde mark waterstofbom ho...\n",
       "3                                            test test\n",
       "4    thank yahoo have toolbar capture urls popups m...\n",
       "Name: token_str, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some packages only want the tokens fed as a string. Others want a list of strings.\n",
    "df['token_str'] = df['tokens'].map(lambda x: ' '.join(x))\n",
    "df['token_str'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pre-Processing\n",
    "Here we convert string labels into numbers (label-encoding). Next we vectorize all words into tf-idf vectors.\n",
    "Note that I dropped all words which appear in over 67% of documents and those that appear in less than 5 documents. This step helps filter out noisy words and only keep the significant ones. \n",
    "max_features determines the max # of words to keep in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y=le.fit_transform(df['gender'])\n",
    "X=df['token_str']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfid = TfidfVectorizer(min_df=5, max_df=0.67, smooth_idf=True,\n",
    "                       norm = 'l2', ngram_range=[1,2], max_features=150000)\n",
    "tfid_train_matrix = tfid.fit_transform(X_train)\n",
    "tfid_test_matrix = tfid.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Machine Learning Model\n",
    "Here I'm using XGBoost's \"boosted random forest\" implementation, which is, so far, the only algorithm that delivers an F1 score over .69. \n",
    "\n",
    "Boosted random forest is simply the normal boosted trees algorithm, but at each cycle, it creates num_parallel_tree mini-decision trees. On this dataset, it's resulted in drastically increased accuracy, but be warned, it's much more computationally intensive. Increased runtimes can be drastically reduced by selecting the 'gpu_hist' method, but currently support for CUDA drivers is mixed.\n",
    "\n",
    "Use the nthread parameter to determine how many CPU cores you want to run the algorithm simultaneously. Currently, XGBoost defaults to (# of cores -1).\n",
    "\n",
    "learning_rate is how much XGBoost learns from the mini decision trees at each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score:  0.6663247762121159\n",
      "F1 score:  0.6989776398571671\n",
      "[[47900 36329]\n",
      " [20321 65771]]\n",
      "CPU times: user 8h 36min 26s, sys: 44.3 s, total: 8h 37min 11s\n",
      "Wall time: 47min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# If your computer has a GPU, you should set the booster parameter to 'gpu_hist', \n",
    "# and possibly bring the subsample size up. With a faster-running tool you could increase the number of estimators\n",
    "# and num_parallel_tree as well.'''\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(n_estimators=500, learning_rate=0.0875, max_depth=6, nthread=11, \n",
    "                    num_parallel_tree=3, subsample=0.85)\n",
    "clf.fit(tfid_train_matrix, y_train)\n",
    "y_preds=clf.predict(tfid_test_matrix)\n",
    "print('ROC score: ', roc_auc_score(y_test, y_preds))\n",
    "print(\"F1 score: \", metrics.f1_score(y_test , y_preds))\n",
    "print(metrics.confusion_matrix(y_test , y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the models here. Do not use built-in .save() methods for machine learning tools because they don't save many important attributes. Use pickle or joblib.\n",
    "#### Saving the entire tf-idf vectorizer would be too large a filesize. So instead save the .vocabulary__, and in the app, load a tf-idf vectorizer with the same settings as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vocab']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the models here\n",
    "from joblib import dump\n",
    "dump(clf, 'xgbooster')\n",
    "#Saving the entire tf-idf vectorizer would make a file too large. So just save the vocabulary, load another vectorizer\n",
    "\n",
    "dump(tfid.vocabulary_, 'vocab')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
