{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "df = pd.read_csv('blogtext.csv', parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 4.83 s, total: 1min 13s\n",
      "Wall time: 52min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Here we import my custom cleaner script, clean.py. I parallelize the function to run faster here, to work when scaling. \n",
    "#Using 3 cores for the task and 1 core to manage the multiprocessing.\n",
    "import clean\n",
    "from joblib import Parallel, delayed\n",
    "df['tokens'] = Parallel(n_jobs=3)(delayed(clean.clean)(line) for line in df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    info have find page psf file have wait until t...\n",
       "1    team member drives van der lang mail ruby die ...\n",
       "2    nader van kernfusie barde mark waterstofbom ho...\n",
       "3                                            test test\n",
       "4    thank yahoo have toolbar capture urls popups m...\n",
       "Name: token_str, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['token_str'] = df['trigrams'].map(lambda x: ' '.join(x))\n",
    "df['token_str'] = df['tokens'].map(lambda x: ' '.join(x))\n",
    "df['token_str'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "# Converting string labels into numbers.\n",
    "y=le.fit_transform(df['gender'])\n",
    "X=df['token_str']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfid = TfidfVectorizer(min_df=5, max_df=0.67, smooth_idf=True,\n",
    "                       norm = 'l2', ngram_range=[1,2], max_features=150000)\n",
    "tfid_train_matrix = tfid.fit_transform(X_train)\n",
    "tfid_test_matrix = tfid.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score:  0.6660686531189777\n",
      "F1 score:  0.7001487110824156\n",
      "[[47513 36576]\n",
      " [20083 66149]]\n",
      "CPU times: user 13h 35min 8s, sys: 30.3 s, total: 13h 35min 38s\n",
      "Wall time: 4h 32min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''Use n_jobs parameter to your # of CPU cores minus 1\n",
    "If your computer has a GPU (which mine doesn't), you should set the booster parameter to 'gpu_hist', \n",
    "and possibly bring the subsample size up. With a faster-running tool you could increase the number of estimators\n",
    "and num_parallel_tree as well.'''\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(n_estimators=500, learning_rate=0.0875, max_depth=6, n_jobs=3, \n",
    "                    num_parallel_tree=4, subsample=0.85)\n",
    "clf.fit(tfid_train_matrix, y_train)\n",
    "y_preds=clf.predict(tfid_test_matrix)\n",
    "print('ROC score: ', roc_auc_score(y_test, y_preds))\n",
    "print(\"F1 score: \", metrics.f1_score(y_test , y_preds))\n",
    "print(metrics.confusion_matrix(y_test , y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump \n",
    "# dump(clf, \"xgbooster\")\n",
    "# dump(tfid, 'vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best results were from tfidf tokenization and XGBoost with boosted random forest implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
